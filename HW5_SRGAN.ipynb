{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW5-SRGAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7XCdqG2VHt3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b00f6a27-098d-4452-8aac-4b994e94fada"
      },
      "source": [
        "from google.colab import drive\n",
        "import json\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF3J3Xd-7WHD"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import save_image\n",
        "from torchvision.models.vgg import vgg19\n",
        "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
        "\n",
        "import os\n",
        "import time\n",
        "from random import seed\n",
        "from util import *\n",
        "\n",
        "seed(11785)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9kPBLCI9w50"
      },
      "source": [
        "#define the GAN architecture and perceptual loss\n",
        "class sub_conv(nn.Conv2d):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias):\n",
        "        super(sub_conv, self).__init__(in_channels = in_channels, out_channels = out_channels, \n",
        "                               kernel_size = kernel_size, stride = stride, padding = (kernel_size) // 2, bias = True)\n",
        "        \n",
        "        self.weight.data = torch.normal(torch.zeros((out_channels, in_channels, kernel_size, kernel_size)), 0.02)\n",
        "        self.bias.data = torch.zeros((out_channels))\n",
        "        \n",
        "        for p in self.parameters():\n",
        "            p.requires_grad = True\n",
        "\n",
        "class conv(nn.Module):\n",
        "    def __init__(self, in_channel, out_channel, kernel_size, BN = False, act = None, stride = 1, bias = True):\n",
        "        super(conv, self).__init__()\n",
        "        m = []\n",
        "        m.append(sub_conv(in_channels = in_channel, out_channels = out_channel, \n",
        "                               kernel_size = kernel_size, stride = stride, padding = (kernel_size) // 2, bias = True))\n",
        "        \n",
        "        if BN:\n",
        "            m.append(nn.BatchNorm2d(num_features = out_channel))\n",
        "        \n",
        "        if act is not None:\n",
        "            m.append(act)\n",
        "        \n",
        "        self.layers = nn.Sequential(*m)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layers(x)\n",
        "        return out\n",
        "        \n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, channels, kernel_size, act = nn.ReLU(inplace = True), bias = True):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.blocks = nn.Sequential(conv(channels, channels, kernel_size, BN = True, act = act),\n",
        "                                    conv(channels, channels, kernel_size, BN = True, act = None))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        res = self.blocks(x)\n",
        "        res += x\n",
        "        return res\n",
        "        \n",
        "class Upsampler(nn.Module):\n",
        "    def __init__(self, channel, kernel_size, scale, act = nn.ReLU(inplace = True)):\n",
        "        super(Upsampler, self).__init__()\n",
        "        self.upsample = nn.Sequential(conv(channel, channel * scale * scale, kernel_size),\n",
        "                                      nn.PixelShuffle(scale),\n",
        "                                      act)\n",
        "    def forward(self, x):\n",
        "        out = self.upsample(x)\n",
        "        return out\n",
        "\n",
        "class discriminator_block(nn.Module):\n",
        "    def __init__(self, in_feats, out_feats, kernel_size, act = nn.LeakyReLU(inplace = True)):\n",
        "        super(discriminator_block, self).__init__()\n",
        "        m = []\n",
        "        m.append(conv(in_feats, out_feats, kernel_size, BN = True, act = act))\n",
        "        m.append(conv(out_feats, out_feats, kernel_size, BN = True, act = act, stride = 2))\n",
        "        self.body = nn.Sequential(*m)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.body(x)\n",
        "        return out\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, img_feat = 3, n_feats = 64, kernel_size = 3, num_block = 16, act = nn.PReLU(), scale=4):\n",
        "        super(Generator, self).__init__()\n",
        "        \n",
        "        self.conv1 = conv(in_channel = img_feat, out_channel = n_feats, kernel_size = 9, BN = False, act = act)\n",
        "\n",
        "        layers = [ResidualBlock(channels = n_feats, kernel_size = 3, act = act) for _ in range(num_block)]\n",
        "        layers.append(conv(in_channel = n_feats, out_channel = n_feats, kernel_size = 3, BN = True, act = None))\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "        upsample_blocks = [Upsampler(channel = n_feats, kernel_size = 3, scale = 2, act = act) for _ in range(2)]\n",
        "\n",
        "        self.tail = nn.Sequential(*upsample_blocks)\n",
        "        \n",
        "        self.last_conv = conv(in_channel = n_feats, out_channel = img_feat, kernel_size = 3, BN = False, act = nn.Tanh())\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        _skip_connection = x\n",
        "\n",
        "        x = self.layers(x)\n",
        "        feat = x + _skip_connection\n",
        "        \n",
        "        x = self.tail(feat)\n",
        "        x = self.last_conv(x)\n",
        "        \n",
        "        return x, feat\n",
        "    \n",
        "class Discriminator(nn.Module):\n",
        "    \n",
        "    def __init__(self, img_feat = 3, n_feats = 64, kernel_size = 3, act = nn.LeakyReLU(inplace = True), num_of_block = 3, patch_size = 96):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.act = act\n",
        "        \n",
        "        layers = []\n",
        "        layers.append(conv(in_channel = img_feat, out_channel = n_feats, kernel_size = 3, BN = False, act = self.act))\n",
        "        layers.append(conv(in_channel = n_feats, out_channel = n_feats, kernel_size = 3, BN = False, act = self.act, stride = 2))\n",
        "        layers.extend([discriminator_block(in_feats = n_feats * (2 ** i), out_feats = n_feats * (2 ** (i + 1)), kernel_size = 3, act = self.act) for i in range(num_of_block)])\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "        \n",
        "        self.linear_size = ((patch_size // (2 ** (num_of_block + 1))) ** 2) * (n_feats * (2 ** num_of_block))\n",
        "        \n",
        "        self.final_layers = nn.Sequential(nn.Linear(self.linear_size, 1024),\n",
        "                                  self.act,\n",
        "                                  nn.Linear(1024, 1),\n",
        "                                  nn.Sigmoid())\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.layers(x)        \n",
        "        x = x.view(-1, self.linear_size)\n",
        "        x = self.final_layers(x)\n",
        "        return x\n",
        "\n",
        "class PerceptualLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PerceptualLoss, self).__init__()\n",
        "\n",
        "        vgg = vgg19(pretrained=True)\n",
        "        loss_network = nn.Sequential(*list(vgg.features)[:31]).eval()\n",
        "        for p in loss_network.parameters():\n",
        "            p.requires_grad = False\n",
        "        self.network = loss_network\n",
        "        self.loss = nn.MSELoss()\n",
        "\n",
        "    def forward(self, high_resolution, fake_high_resolution):\n",
        "        perception_loss = self.loss(self.network(fake_high_resolution), self.network(high_resolution))\n",
        "        return perception_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7ojz91HdJsJ"
      },
      "source": [
        "# parameter\n",
        "class args():\n",
        "  res_num = 16  # number of residual block\n",
        "  num_workers = 0  # number of epochs to train for\n",
        "  batch_size = 16\n",
        "  sample_batch_size = 1\n",
        "  L2_coeff = 1.0\n",
        "  adv_coeff = 1e-3\n",
        "  vgg_rescale_coeff = 0.006\n",
        "  pre_train_epoch = 10  # epochs in current train (load model)\n",
        "  fine_train_epoch = 60\n",
        "  checkpoint_dir = 'SRGAN/checkpoints' #path to saved models\n",
        "  sample_dir = 'samples'  #folder to output images and model checkpoints\n",
        "  scale = 4\n",
        "  patch_size = 32 # lr patch_size\n",
        "  load_model_epoch = False  # model epoch to load, start from scratch if False\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mpyB0Tz-QEH"
      },
      "source": [
        "# define the function for training and validation process\n",
        "def train_valid(args):\n",
        "    train_dataset = Datasets('train')\n",
        "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=args.batch_size, shuffle=True)\n",
        "    dev_dataset = Datasets('valid')\n",
        "    dev_loader = torch.utils.data.DataLoader(dataset=dev_dataset, batch_size=args.sample_batch_size, shuffle=True)\n",
        "\n",
        "    generator = Generator(img_feat = 3, n_feats = 64, kernel_size = 3, num_block = args.res_num, scale=args.scale).to(args.device)\n",
        "    generator.train()\n",
        "    \n",
        "    l2_loss = nn.MSELoss()\n",
        "    g_optim = optim.Adam(generator.parameters(), lr = 1e-4)\n",
        "        \n",
        "    pre_epoch = 0\n",
        "    fine_epoch = 0\n",
        "    \n",
        "    #### Train using L2_loss\n",
        "    while pre_epoch < args.pre_train_epoch:\n",
        "        start_time = time.time()\n",
        "        for i, tr_data in enumerate(train_loader):\n",
        "            # if i == 5: break\n",
        "            gt = tr_data['hr'].to(args.device)\n",
        "            lr = tr_data['lr'].to(args.device)\n",
        "\n",
        "            output, _ = generator(lr)\n",
        "            loss = l2_loss(gt, output)\n",
        "\n",
        "            g_optim.zero_grad()\n",
        "            loss.backward()\n",
        "            g_optim.step()\n",
        "\n",
        "        pre_epoch += 1\n",
        "        end_time = time.time()\n",
        "        print('pre_epoch:', pre_epoch)\n",
        "        print('time: ', end_time-start_time)\n",
        "        print(loss.item())\n",
        "\n",
        "        print('=========')\n",
        "\n",
        "    #### Train using perceptual & adversarial loss\n",
        "    \n",
        "    discriminator = Discriminator(patch_size = args.patch_size * args.scale).to(args.device)\n",
        "    discriminator.train()\n",
        "    \n",
        "    d_optim = optim.Adam(discriminator.parameters(), lr = 1e-4)\n",
        "    scheduler = optim.lr_scheduler.StepLR(g_optim, step_size = args.fine_train_epoch//4, gamma = 0.1)\n",
        "\n",
        "    VGG_loss = PerceptualLoss().to(args.device)\n",
        "    cross_ent = nn.BCELoss()\n",
        "    \n",
        "    while fine_epoch < args.fine_train_epoch:\n",
        "        start_time = time.time()\n",
        "        generator.train()\n",
        "        discriminator.train()\n",
        "        total_g_loss, total_d_loss = 0, 0\n",
        "        real_label = torch.ones((args.batch_size, 1)).to(args.device)\n",
        "        fake_label = torch.zeros((args.batch_size, 1)).to(args.device)\n",
        "        for i, tr_data in enumerate(train_loader):\n",
        "            # if i == 5: break\n",
        "            gt = tr_data['hr'].to(args.device)\n",
        "            lr = tr_data['lr'].to(args.device)\n",
        "                        \n",
        "            ## Training Discriminator\n",
        "            output, _ = generator(lr)\n",
        "            fake_prob, real_prob = discriminator(output), discriminator(gt)\n",
        "            \n",
        "            d_loss = cross_ent(real_prob, real_label) + cross_ent(fake_prob, fake_label)\n",
        "\n",
        "            total_d_loss += d_loss.item()\n",
        "            g_optim.zero_grad()\n",
        "            d_optim.zero_grad()\n",
        "            d_loss.backward()\n",
        "            d_optim.step()\n",
        "            \n",
        "            ## Training Generator\n",
        "            output, _ = generator(lr)\n",
        "            fake_prob = discriminator(output)\n",
        "\n",
        "            _percep_loss = VGG_loss((gt + 1.0) / 2.0, (output + 1.0) / 2.0)\n",
        "\n",
        "            L2_loss = l2_loss(output, gt)\n",
        "            percep_loss = args.vgg_rescale_coeff * _percep_loss\n",
        "            adversarial_loss = args.adv_coeff * cross_ent(fake_prob, real_label)\n",
        "            \n",
        "            g_loss = percep_loss + adversarial_loss + L2_loss\n",
        "            \n",
        "            total_g_loss += g_loss.item()\n",
        "            g_optim.zero_grad()\n",
        "            d_optim.zero_grad()\n",
        "            g_loss.backward()\n",
        "            g_optim.step()\n",
        "        end_time = time.time()\n",
        "        print('fine_epoch:', fine_epoch)\n",
        "            \n",
        "        print('training time: ', end_time-start_time)\n",
        "        print('total g loss:', total_g_loss/len(train_loader))\n",
        "        print('total d loss:', total_d_loss/len(train_loader))\n",
        "        print('====')\n",
        "\n",
        "        generator.eval()\n",
        "        discriminator.eval()\n",
        "        total_g_loss, total_d_loss, PSNR, SSIM = 0, 0, 0, 0\n",
        "        real_label = torch.ones((args.sample_batch_size, 1)).to(args.device)\n",
        "        fake_label = torch.zeros((args.sample_batch_size, 1)).to(args.device)\n",
        "        for i, tr_data in enumerate(dev_loader):\n",
        "            # if i == 5: break\n",
        "            gt = tr_data['hr'].to(args.device)\n",
        "            lr = tr_data['lr'].to(args.device)\n",
        "                        \n",
        "            ## Training Discriminator\n",
        "            output, _ = generator(lr)\n",
        "            fake_prob, real_prob = discriminator(output), discriminator(gt)\n",
        "            \n",
        "            d_loss = cross_ent(real_prob, real_label) + cross_ent(fake_prob, fake_label)\n",
        "\n",
        "            total_d_loss += d_loss.item()\n",
        "            g_optim.zero_grad()\n",
        "            d_optim.zero_grad()\n",
        "            \n",
        "            ## Training Generator\n",
        "            output, _ = generator(lr)\n",
        "            fake_prob = discriminator(output)\n",
        "\n",
        "            _percep_loss = VGG_loss((gt + 1.0) / 2.0, (output + 1.0) / 2.0)\n",
        "\n",
        "            L2_loss = l2_loss(output, gt)\n",
        "            percep_loss = args.vgg_rescale_coeff * _percep_loss\n",
        "            adversarial_loss = args.adv_coeff * cross_ent(fake_prob, real_label)\n",
        "            \n",
        "            g_loss = percep_loss + adversarial_loss + L2_loss\n",
        "            \n",
        "            total_g_loss += g_loss.item()\n",
        "            g_optim.zero_grad()\n",
        "            d_optim.zero_grad()\n",
        "\n",
        "            gt = gt.permute(0, 2, 3, 1).cpu().detach().numpy()\n",
        "            output = output.permute(0, 2, 3, 1).cpu().detach().numpy()\n",
        "\n",
        "            PSNR += peak_signal_noise_ratio(gt[0], output[0])\n",
        "            SSIM += structural_similarity(gt[0], output[0], multichannel=True)\n",
        "\n",
        "        scheduler.step()\n",
        "        fine_epoch += 1\n",
        "        end_time = time.time()\n",
        "\n",
        "            \n",
        "        print('time: ', time.time()-end_time)\n",
        "        print('total g loss:', total_g_loss/len(dev_loader))\n",
        "        print('total d loss:', total_d_loss/len(dev_loader))\n",
        "        print('PSNR:', PSNR/len(dev_loader))\n",
        "        print('SSIM:', SSIM/len(dev_loader))   \n",
        "\n",
        "        %cd ./gdrive/My Drive/11785/HW5/\n",
        "        torch.save(generator.state_dict(), os.path.join(args.checkpoint_dir, f\"generator_{fine_epoch}.pth\"))\n",
        "        torch.save(discriminator.state_dict(), os.path.join(args.checkpoint_dir, f\"discriminator_{fine_epoch}.pth\"))\n",
        "        %cd /content\n",
        "\n",
        "        print('=========')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtaQ8KA9FZ_T"
      },
      "source": [
        "# download the dataset and do the data preprocessing (crop or resize)\n",
        "download_dataset()\n",
        "\n",
        "print('[!] Making Patches')\n",
        "\n",
        "resize_image('train_hr', args.patch_size*args.scale)\n",
        "resize_image('train_lr', args.patch_size)\n",
        "resize_image('valid_hr', args.patch_size*args.scale)\n",
        "resize_image('valid_lr', args.patch_size)\n",
        "\n",
        "#train and save the model\n",
        "torch.cuda.empty_cache()\n",
        "train_valid(args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKy7OZmGzomU"
      },
      "source": [
        "%cd /content/gdrive/My Drive/11785/HW5\n",
        "\n",
        "# change to the google drive folder to generate test image\n",
        "def test(target_folder, load_model_epoch, args, resize=False): # generate image from testset\n",
        "    if resize:\n",
        "      resize_image('test_lr/'+target_folder, resize, 'test_resize/'+target_folder)\n",
        "      test_dataset = Datasets(mode='test_resize/'+target_folder)\n",
        "    else:\n",
        "      test_dataset = Datasets(mode='test_lr/'+target_folder)\n",
        "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=args.sample_batch_size)\n",
        "    if not os.path.exists('test_results/'+target_folder):\n",
        "      os.makedirs('test_results/'+target_folder)\n",
        "    \n",
        "    model = Generator(img_feat=3, n_feats=64, kernel_size=3, num_block=args.res_num, scale=args.scale).to(args.device)\n",
        "    model.load_state_dict(torch.load(os.path.join(args.checkpoint_dir, f'generator_{load_model_epoch}.pth')))\n",
        "    with torch.no_grad():\n",
        "      model.eval()\n",
        "      for step, image in enumerate(test_loader):\n",
        "        lr = image['lr'].to(args.device)\n",
        "        image_name = image['hr']\n",
        "        outputs, _ = model(lr)\n",
        "        save_image(outputs, os.path.join('test_results/'+target_folder, image_name[0]))\n",
        "\n",
        "target_folder = ['large_test', 'small_test', 'comics', 'structures']\n",
        "load_model_epoch = 59\n",
        "for t in target_folder:\n",
        "    test(t, load_model_epoch, args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgvNnv5VFj2B"
      },
      "source": [
        "# Using the provided script to calcualte test PSNR and SSIM\n",
        "TEST_LABEL_PATH = 'test_labels/small_test/'\n",
        "TEST_RESULT_PATH = 'test_results/small_test/'\n",
        "TEST_RESTORE_PATH =  'test_restore_results/small_test/'\n",
        "\n",
        "\n",
        "scores = compute_scores(TEST_LABEL_PATH, TEST_RESULT_PATH, TEST_RESTORE_PATH)\n",
        "print('small_test: ', scores)\n",
        "\n",
        "TEST_LABEL_PATH = 'test_labels/large_test/'\n",
        "TEST_RESULT_PATH = 'test_results/large_test/'\n",
        "TEST_RESTORE_PATH =  'test_restore_results/large_test/'\n",
        "\n",
        "scores = compute_scores(TEST_LABEL_PATH, TEST_RESULT_PATH, TEST_RESTORE_PATH)\n",
        "print('large_test: ', scores)\n",
        "\n",
        "TEST_LABEL_PATH = 'test_labels/comics/'\n",
        "TEST_RESULT_PATH = 'test_results/comics/'\n",
        "TEST_RESTORE_PATH =  'test_restore_results/comics/'\n",
        "\n",
        "scores = compute_scores(TEST_LABEL_PATH, TEST_RESULT_PATH, TEST_RESTORE_PATH)\n",
        "print('comic: ', scores)\n",
        "\n",
        "TEST_LABEL_PATH = 'test_labels/structures/'\n",
        "TEST_RESULT_PATH = 'test_results/structures/'\n",
        "TEST_RESTORE_PATH =  'test_restore_results/structures/'\n",
        "\n",
        "scores = compute_scores(TEST_LABEL_PATH, TEST_RESULT_PATH, TEST_RESTORE_PATH)\n",
        "print('structures: ', scores)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}